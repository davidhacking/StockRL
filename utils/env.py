from typing import Any, List, Tuple
import numpy as np
import pandas as pd
import random
from copy import deepcopy
import gym
import time
from gym import spaces

from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv
from stable_baselines3.common.logger import Logger, configure

log_path = './logs/'  # ÊåáÂÆöÊó•Âøó‰øùÂ≠òÁöÑË∑ØÂæÑ
logger = configure(log_path, ["stdout", "csv", "tensorboard"])

class StockLearningEnv(gym.Env):
    """ÊûÑÂª∫Âº∫ÂåñÂ≠¶‰π†‰∫§ÊòìÁéØÂ¢É

        Attributes
            df: ÊûÑÂª∫ÁéØÂ¢ÉÊó∂ÊâÄÈúÄË¶ÅÁî®Âà∞ÁöÑË°åÊÉÖÊï∞ÊçÆ
            buy_cost_pct: ‰π∞ËÇ°Á•®Êó∂ÁöÑÊâãÁª≠Ë¥π
            sell_cost_pct: ÂçñËÇ°Á•®Êó∂ÁöÑÊâãÁª≠Ë¥π
            date_col_name: Êó•ÊúüÂàóÁöÑÂêçÁß∞
            hmax: ÊúÄÂ§ßÂèØ‰∫§ÊòìÁöÑÊï∞Èáè
            print_verbosity: ÊâìÂç∞ÁöÑÈ¢ëÁéá
            initial_amount: ÂàùÂßãËµÑÈáëÈáè
            daily_information_cols: ÊûÑÂª∫Áä∂ÊÄÅÊó∂ÊâÄËÄÉËôëÁöÑÂàó
            cache_indicator_data: ÊòØÂê¶ÊääÊï∞ÊçÆÊîæÂà∞ÂÜÖÂ≠ò‰∏≠
            random_start: ÊòØÂê¶ÈöèÊú∫‰ΩçÁΩÆÂºÄÂßã‰∫§ÊòìÔºàËÆ≠ÁªÉÂíåÂõûÊµãÁéØÂ¢ÉÂàÜÂà´‰∏∫TrueÂíåFalseÔºâ
            patient: ÊòØÂê¶Âú®ËµÑÈáë‰∏çÂ§üÊó∂‰∏çÊâßË°å‰∫§ÊòìÊìç‰ΩúÔºåÁ≠âÂà∞ÊúâË∂≥Â§üËµÑÈáëÊó∂ÂÜçÊâßË°å
            currency: Ë¥ßÂ∏ÅÂçï‰Ωç
    """

    metadata = {"render.modes": ["human"]}
    def __init__(
        self,
        df: pd.DataFrame,
        buy_cost_pct: float = 3e-3,
        sell_cost_pct: float = 3e-3,
        date_col_name: str = "date",
        hmax: int = 10,
        print_verbosity: int = 10,
        initial_amount: int = 1e6,
        daily_information_cols: List = ["open", "close", "high", "low", "volume"],
        cache_indicator_data: bool = True,
        random_start: bool = True,
        patient: bool = False,
        currency: str = "Ôø•",
        alpha: float = 1.0
    ) -> None:
        self.df = df
        self.stock_col = "tic"
        self.assets = df[self.stock_col].unique()
        self.dates = df[date_col_name].sort_values().unique()
        self.random_start = random_start
        self.patient = patient
        self.currency = currency
        self.df = self.df.set_index(date_col_name)
        self.hmax = hmax
        self.initial_amount = initial_amount
        self.print_verbosity = print_verbosity
        self.buy_cost_pct = buy_cost_pct
        self.sell_cost_pct = sell_cost_pct
        self.daily_information_cols = daily_information_cols
        D = len(self.assets) # ËÇ°Á•®Êï∞Èáè
        b = 1 # ‰ΩôÈ¢ù
        h = D # ÊØèÂè™ËÇ°Á•®ÁöÑÊåÅ‰ªì‰ø°ÊÅØ
        p = D * len(self.daily_information_cols) # ËÇ°Á•®ÁöÑ‰ª∑Ê†º‰ø°ÊÅØ
        self.state_space = (
            b + h + p
        )
        """
        ÂØπ‰∫éÊüêÊîØËÇ°Á•®ÔºåÂä®‰ΩúÁ©∫Èó¥ÁöÑÂÆö‰πâ‰∏∫ {‚àík, . . . , ‚àí1, 0, 1, . . . , k}ÔºåÂÖ∂‰∏≠ ùëò Âíå ‚àíùëò Ë°®Á§∫Êàë
        ‰ª¨ÂèØ‰ª•Ë¥≠‰π∞ÂíåÂá∫ÂîÆÁöÑËÇ°‰ªΩÊï∞Èáè k = hmaxÔºåÂõ†‰∏∫ RL ÁÆóÊ≥ï A2C Âíå PPO Áõ¥Êé•‰ΩøÁî®È´òÊñØÂàÜÂ∏ÉËæìÂá∫Á≠ñÁï•ÁöÑÂàÜÂ∏ÉÔºå
        ÈúÄË¶ÅËøõË°åÂΩí‰∏ÄÂåñÂ§ÑÁêÜÔºåÊâÄ‰ª•Âä®‰ΩúÁ©∫Èó¥Ë¢´ÂΩí‰∏ÄÂåñ‰∏∫ [‚àí1,1]„ÄÇ
        """
        self.action_space = spaces.Box(low=-1, high=1, shape=(D,))
        self.observation_space = spaces.Box(
            low=-np.inf, high=np.inf, shape=(self.state_space,)
        )
        self.turbulence = 0
        self.episode = -1
        self.episode_history = []
        self.printed_header = False
        self.cache_indicator_data = cache_indicator_data
        self.cached_data = None
        self.max_total_assets = 0
        self.alpha = alpha
        if self.cache_indicator_data:
            """cashing data ÁöÑÁªìÊûÑ:
               [[date1], [date2], [date3], ...]
               date1 : [stock1 * cols, stock2 * cols, ...]
            """
            print("Âä†ËΩΩÊï∞ÊçÆÁºìÂ≠ò")
            self.cached_data = [
                self.get_date_vector(i) for i, _ in enumerate(self.dates)
            ]
            print("Êï∞ÊçÆÁºìÂ≠òÊàêÂäü!")
        
    def seed(self, seed: Any = None) -> None:
        """ËÆæÁΩÆÈöèÊú∫ÁßçÂ≠ê"""
        if seed is None:
            seed = int(round(time.time() * 1000))
        random.seed(seed)
    
    @property
    def current_step(self) -> int:
        """ÂΩìÂâçÂõûÂêàÁöÑËøêË°åÊ≠•Êï∞"""
        return self.date_index - self.starting_point
    
    @property
    def cash_on_hand(self) -> float:
        """ÂΩìÂâçÊã•ÊúâÁöÑÁé∞Èáë"""
        return self.state_memory[-1][0]
    
    @property
    def holdings(self) -> List:
        """ÂΩìÂâçÁöÑÊåÅ‰ªìÊï∞ÊçÆ"""
        return self.state_memory[-1][1: len(self.assets) + 1]

    @property
    def closings(self) -> List:
        """ÊØèÊîØËÇ°Á•®ÂΩìÂâçÁöÑÊî∂Áõò‰ª∑"""
        return np.array(self.get_date_vector(self.date_index, cols=["close"]))

    def get_date_vector(self, date: int, cols: List = None) -> List:
        """Ëé∑Âèñ date ÈÇ£Â§©ÁöÑË°åÊÉÖÊï∞ÊçÆ"""
        if(cols is None) and (self.cached_data is not None):
            return self.cached_data[date]
        else:
            date = self.dates[date]
            if cols is None:
                cols = self.daily_information_cols
            trunc_df = self.df.loc[[date]]
            res = []
            for asset in self.assets:
                tmp_res = trunc_df[trunc_df[self.stock_col] == asset]
                res += tmp_res.loc[date, cols].tolist()
            assert len(res) == len(self.assets) * len(cols)
            return res
    
    def reset(self) -> np.ndarray:
        self.seed()
        self.sum_trades = 0
        self.max_total_assets = self.initial_amount
        if self.random_start:
            self.starting_point = random.choice(range(int(len(self.dates) * 0.5)))
        else:
            self.starting_point = 0
        self.date_index = self.starting_point
        self.turbulence = 0
        self.episode += 1
        self.actions_memory = []
        self.transaction_memory = []
        self.state_memory = []
        self.account_information = {
            "cash": [],
            "asset_value": [],
            "total_assets": [],
            "reward": []
        }
        init_state = np.array(
            [self.initial_amount] 
            + [0] * len(self.assets)
            + self.get_date_vector(self.date_index)
        )
        self.state_memory.append(init_state)
        return init_state

    def log_step(
        self, reason: str, terminal_reward: float=None
        ) -> None:
        """ÊâìÂç∞"""
        if terminal_reward is None:
            terminal_reward = self.account_information["reward"][-1]
        
        assets = self.account_information["total_assets"][-1]
        tmp_retreat_ptc = assets / self.max_total_assets - 1
        retreat_pct = tmp_retreat_ptc if assets < self.max_total_assets else 0
        gl_pct = self.account_information["total_assets"][-1] / self.initial_amount

        rec = [
            self.episode,
            self.date_index - self.starting_point,
            reason,
            f"{self.currency}{'{:0,.0f}'.format(float(self.account_information['cash'][-1]))}",
            f"{self.currency}{'{:0,.0f}'.format(float(assets))}",
            f"{terminal_reward*100:0.5f}%",
            f"{(gl_pct - 1)*100:0.5f}%",
            f"{retreat_pct*100:0.2f}%"
        ]
        self.episode_history.append(rec)
        print(self.template.format(*rec))

    def return_terminal(
        self, reason: str = "Last Date", reward: int = 0
    ) -> Tuple[List, float, bool, dict]:
        """terminal ÁöÑÊó∂ÂÄôÊâßË°åÁöÑÊìç‰Ωú"""
        state = self.state_memory[-1]
        self.log_step(reason=reason, terminal_reward=reward)
        gl_pct = self.account_information["total_assets"][-1] / self.initial_amount
        logger.record("environment/GainLoss_pct", (gl_pct - 1) * 100)
        logger.record(
            "environment/total_assets",
            int(self.account_information["total_assets"][-1])
        )
        reward_pct = gl_pct
        logger.record("environment/total_reward_pct", (reward_pct - 1) * 100)
        logger.record("environment/total_trades", self.sum_trades)
        logger.record(
            "environment/avg_daily_trades",
            self.sum_trades / (self.current_step)
        )
        logger.record(
            "environment/avg_daily_trades_per_asset",
            self.sum_trades / (self.current_step) / len(self.assets)
        )
        logger.record("environment/completed_steps", self.current_step)
        logger.record(
            "environment/sum_rewards", np.sum(self.account_information["reward"])
        )
        logger.record(
            "environment/retreat_proportion",
            self.account_information["total_assets"][-1] / self.max_total_assets
        )

        return state, reward, True, {}

    def log_header(self) -> None:
        """Log ÁöÑÂàóÂêç"""
        if not self.printed_header:
            self.template = "{0:4}|{1:4}|{2:15}|{3:15}|{4:15}|{5:10}|{6:10}|{7:10}"
            # 0, 1, 2, ... ÊòØÂ∫èÂè∑
            # 4, 4, 15, ... ÊòØÂç†‰ΩçÊ†ºÁöÑÂ§ßÂ∞è
            print(
                self.template.format(
                    "EPISODE",
                    "STEPS",
                    "TERMINAL_REASON",
                    "CASH",
                    "TOT_ASSETS",
                    "TERMINAL_REWARD",
                    "GAINLOSS_PCT",
                    "RETREAT_PROPORTION"
                )
            )
            self.printed_header = True

    def get_reward(self) -> float:
        """
        Ëé∑ÂèñÂ•ñÂä±ÂÄº=Á¥ØËÆ°Êî∂ÁõäÁéá - ÂΩìÂâçÂõûÊí§Áéá‰Ωú‰∏∫Â•ñÂä±ÂÄº
        Âú®ËÇ°Á•®‰∫§Êòì‰∏≠ÔºåÊàë‰ª¨ÂèØ‰ª•ÊääÊô∫ËÉΩ‰ΩìÂèñÂæóÁöÑÁ¥ØËÆ°Êî∂ÁõäÁéá‰Ωú‰∏∫Â•ñÂä±ÂÄºÔºåËøôÈùûÂ∏∏ÂêàÁêÜ„ÄÇ
        ‰ΩÜ‰∏∫‰∫ÜËÆ©Êî∂ÁõäÊõ¥Âä†Á®≥ÂÅ•ÔºåÊàë‰ª¨ËøòÂèØ‰ª•Âú®Â•ñÂä±ÂÄº‰∏≠Âä†ÂÖ•ÂΩìÂâçÂõûÊí§ÁéáÔºå‰Ωú‰∏∫Ë¥üÁöÑÂ•ñÂä±ÂÄºÔºå‰πüÂèØ‰ª•ËØ¥ÊòØÊÉ©ÁΩöÂÄº„ÄÇ
        """
        if self.current_step == 0:
            return 0
        else:
            assets = self.account_information["total_assets"][-1]
            retreat = 0
            if assets >= self.max_total_assets:
                self.max_total_assets = assets
            else:
                retreat = assets / self.max_total_assets - 1
            reward = assets / self.initial_amount - 1
            reward += self.alpha * retreat
            return reward

    def get_transactions(self, actions: np.ndarray) -> np.ndarray:
        """Ëé∑ÂèñÂÆûÈôÖ‰∫§ÊòìÁöÑËÇ°Êï∞"""
        self.actions_memory.append(actions)
        actions = actions * self.hmax

        # Êî∂Áõò‰ª∑‰∏∫ 0 ÁöÑ‰∏çËøõË°å‰∫§Êòì
        actions = np.where(self.closings > 0, actions, 0)

        # ÂéªÈô§Ë¢´Èô§Êï∞‰∏∫ 0 ÁöÑË≠¶Âëä
        out = np.zeros_like(actions)
        zero_or_not = self.closings != 0
        actions = np.divide(actions, self.closings, out=out, where = zero_or_not)
        
        # ‰∏çËÉΩÂçñÁöÑÊØîÊåÅ‰ªìÁöÑÂ§ö
        actions = np.maximum(actions, -np.array(self.holdings))

        # Â∞Ü -0 ÁöÑÂÄºÂÖ®ÈÉ®ÁΩÆ‰∏∫ 0
        actions[actions == -0] = 0

        return actions

    def step(
        self, actions: np.ndarray
    ) -> Tuple[List, float, bool, dict]:
        self.sum_trades += np.sum(np.abs(actions))
        self.log_header()
        if(self.current_step + 1) % self.print_verbosity == 0:
            self.log_step(reason="update")
        if self.date_index == len(self.dates) - 1:
            return self.return_terminal(reward=self.get_reward())
        else:
            begin_cash = self.cash_on_hand
            assert min(self.holdings) >= 0
            assert_value = np.dot(self.holdings, self.closings)
            self.account_information["cash"].append(begin_cash)
            self.account_information["asset_value"].append(assert_value)
            self.account_information["total_assets"].append(begin_cash + assert_value)
            reward = self.get_reward()
            self.account_information["reward"].append(reward)

            transactions = self.get_transactions(actions)
            sells = -np.clip(transactions, -np.inf, 0)
            proceeds = np.dot(sells, self.closings)
            costs = proceeds * self.sell_cost_pct
            coh = begin_cash + proceeds # ËÆ°ÁÆóÁé∞ÈáëÁöÑÊï∞Èáè

            buys = np.clip(transactions, 0, np.inf)
            spend = np.dot(buys, self.closings)
            costs += spend * self.buy_cost_pct

            if (spend + costs) > coh: # Â¶ÇÊûú‰π∞‰∏çËµ∑
                if self.patient:
#                     self.log_step(reason="CASH SHORTAGE")
                    transactions = np.where(transactions > 0, 0, transactions)
                    spend = 0
                    costs = 0
                else:
                    return self.return_terminal(
                        reason="CASH SHORTAGE", reward=self.get_reward()
                    )
            self.transaction_memory.append(transactions)
            assert (spend + costs) <= coh
            coh = coh - spend - costs
            holdings_updated = self.holdings + transactions
            self.date_index += 1
            state = (
                [coh] + list(holdings_updated) + self.get_date_vector(self.date_index)
            )
            self.state_memory.append(state)
            return state, reward, False, {}

    def get_sb_env(self) -> Tuple[Any, Any]:
        def get_self():
            return deepcopy(self)
        
        e = DummyVecEnv([get_self])
        obs = e.reset()
        return e, obs

    def get_multiproc_env(
        self, n: int = 10
    ) -> Tuple[Any, Any]:
        def get_self():
            return deepcopy(self)
        
        e = SubprocVecEnv([get_self for _ in range(n)], start_method="fork")
        obs = e.reset()
        return e, obs
    
    def save_asset_memory(self) -> pd.DataFrame:
        if self.current_step == 0:
            return None
        else:
            self.account_information["date"] = self.dates[
                -len(self.account_information["cash"]):
            ]
            return pd.DataFrame(self.account_information)
    
    def save_action_memory(self) -> pd.DataFrame:
        if self.current_step == 0:
            return None
        else:
            return pd.DataFrame(
                {
                    "date": self.dates[-len(self.account_information["cash"]):],
                    "actions": self.actions_memory,
                    "transactions": self.transaction_memory
                }
            )