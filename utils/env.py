from typing import Any, List, Tuple
import numpy as np
import pandas as pd
import random
from copy import deepcopy
import gym
import time
from gym import spaces

from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv
from stable_baselines3.common.logger import Logger, configure

log_path = './logs/'  # æŒ‡å®šæ—¥å¿—ä¿å­˜çš„è·¯å¾„
logger = configure(log_path, ["stdout", "csv", "tensorboard"])

class StockLearningEnv(gym.Env):
    """æ„å»ºå¼ºåŒ–å­¦ä¹ äº¤æ˜“ç¯å¢ƒ

        Attributes
            df: æ„å»ºç¯å¢ƒæ—¶æ‰€éœ€è¦ç”¨åˆ°çš„è¡Œæƒ…æ•°æ®
            buy_cost_pct: ä¹°è‚¡ç¥¨æ—¶çš„æ‰‹ç»­è´¹
            sell_cost_pct: å–è‚¡ç¥¨æ—¶çš„æ‰‹ç»­è´¹
            date_col_name: æ—¥æœŸåˆ—çš„åç§°
            hmax: æœ€å¤§å¯äº¤æ˜“çš„æ•°é‡
            print_verbosity: æ‰“å°çš„é¢‘ç‡
            initial_amount: åˆå§‹èµ„é‡‘é‡
            daily_information_cols: æ„å»ºçŠ¶æ€æ—¶æ‰€è€ƒè™‘çš„åˆ—
            cache_indicator_data: æ˜¯å¦æŠŠæ•°æ®æ”¾åˆ°å†…å­˜ä¸­
            random_start: æ˜¯å¦éšæœºä½ç½®å¼€å§‹äº¤æ˜“ï¼ˆè®­ç»ƒå’Œå›æµ‹ç¯å¢ƒåˆ†åˆ«ä¸ºTrueå’ŒFalseï¼‰
            patient: æ˜¯å¦åœ¨èµ„é‡‘ä¸å¤Ÿæ—¶ä¸æ‰§è¡Œäº¤æ˜“æ“ä½œï¼Œç­‰åˆ°æœ‰è¶³å¤Ÿèµ„é‡‘æ—¶å†æ‰§è¡Œ
            currency: è´§å¸å•ä½
    """

    metadata = {"render.modes": ["human"]}
    def __init__(
        self,
        df: pd.DataFrame,
        buy_cost_pct: float = 3e-3,
        sell_cost_pct: float = 3e-3,
        date_col_name: str = "date",
        hmax: int = 10,
        print_verbosity: int = 10,
        initial_amount: int = 1e6,
        daily_information_cols: List = ["open", "close", "high", "low", "volume"],
        cache_indicator_data: bool = True,
        random_start: bool = True,
        patient: bool = False,
        currency: str = "ï¿¥"
    ) -> None:
        self.df = df
        self.stock_col = "tic"
        self.assets = df[self.stock_col].unique()
        self.dates = df[date_col_name].sort_values().unique()
        self.random_start = random_start
        self.patient = patient
        self.currency = currency
        self.df = self.df.set_index(date_col_name)
        self.hmax = hmax
        self.initial_amount = initial_amount
        self.print_verbosity = print_verbosity
        self.buy_cost_pct = buy_cost_pct
        self.sell_cost_pct = sell_cost_pct
        self.daily_information_cols = daily_information_cols
        D = len(self.assets) # è‚¡ç¥¨æ•°é‡
        b = 1 # ä½™é¢
        h = D # æ¯åªè‚¡ç¥¨çš„æŒä»“ä¿¡æ¯
        p = D * len(self.daily_information_cols) # è‚¡ç¥¨çš„ä»·æ ¼ä¿¡æ¯
        self.state_space = (
            b + h + p
        )
        """
        å¯¹äºæŸæ”¯è‚¡ç¥¨ï¼ŒåŠ¨ä½œç©ºé—´çš„å®šä¹‰ä¸º {âˆ’k, . . . , âˆ’1, 0, 1, . . . , k}ï¼Œå…¶ä¸­ ğ‘˜ å’Œ âˆ’ğ‘˜ è¡¨ç¤ºæˆ‘
        ä»¬å¯ä»¥è´­ä¹°å’Œå‡ºå”®çš„è‚¡ä»½æ•°é‡ k <= hmaxï¼Œå› ä¸º RL ç®—æ³• A2C å’Œ PPO ç›´æ¥ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒè¾“å‡ºç­–ç•¥çš„åˆ†å¸ƒï¼Œ
        éœ€è¦è¿›è¡Œå½’ä¸€åŒ–å¤„ç†ï¼Œæ‰€ä»¥åŠ¨ä½œç©ºé—´è¢«å½’ä¸€åŒ–ä¸º [âˆ’1,1]ã€‚
        """
        self.action_space = spaces.Box(low=-1, high=1, shape=(D,))
        self.observation_space = spaces.Box(
            low=-np.inf, high=np.inf, shape=(self.state_space,)
        )
        self.turbulence = 0
        self.episode = -1
        self.episode_history = []
        self.printed_header = False
        self.cache_indicator_data = cache_indicator_data
        self.cached_data = None
        self.max_total_assets = 0
        if self.cache_indicator_data:
            """cashing data çš„ç»“æ„:
               [[date1], [date2], [date3], ...]
               date1 : [stock1 * cols, stock2 * cols, ...]
            """
            print("åŠ è½½æ•°æ®ç¼“å­˜")
            self.cached_data = [
                self.get_date_vector(i) for i, _ in enumerate(self.dates)
            ]
            print("æ•°æ®ç¼“å­˜æˆåŠŸ!")
        
    def seed(self, seed: Any = None) -> None:
        """è®¾ç½®éšæœºç§å­"""
        if seed is None:
            seed = int(round(time.time() * 1000))
        random.seed(seed)
    
    @property
    def current_step(self) -> int:
        """å½“å‰å›åˆçš„è¿è¡Œæ­¥æ•°"""
        return self.date_index - self.starting_point
    
    @property
    def cash_on_hand(self) -> float:
        """å½“å‰æ‹¥æœ‰çš„ç°é‡‘"""
        return self.state_memory[-1][0]
    
    @property
    def holdings(self) -> List:
        """å½“å‰çš„æŒä»“æ•°æ®"""
        return self.state_memory[-1][1: len(self.assets) + 1]

    @property
    def closings(self) -> List:
        """æ¯æ”¯è‚¡ç¥¨å½“å‰çš„æ”¶ç›˜ä»·"""
        return np.array(self.get_date_vector(self.date_index, cols=["close"]))

    def get_date_vector(self, date: int, cols: List = None) -> List:
        """è·å– date é‚£å¤©çš„è¡Œæƒ…æ•°æ®"""
        if(cols is None) and (self.cached_data is not None):
            return self.cached_data[date]
        else:
            date = self.dates[date]
            if cols is None:
                cols = self.daily_information_cols
            trunc_df = self.df.loc[[date]]
            res = []
            for asset in self.assets:
                tmp_res = trunc_df[trunc_df[self.stock_col] == asset]
                res += tmp_res.loc[date, cols].tolist()
            assert len(res) == len(self.assets) * len(cols)
            return res
    
    def reset(self) -> np.ndarray:
        self.seed()
        self.sum_trades = 0
        self.max_total_assets = self.initial_amount
        if self.random_start:
            self.starting_point = random.choice(range(int(len(self.dates) * 0.5)))
        else:
            self.starting_point = 0
        self.date_index = self.starting_point
        self.turbulence = 0
        self.episode += 1
        self.actions_memory = []
        self.transaction_memory = []
        self.state_memory = []
        self.account_information = {
            "cash": [],
            "asset_value": [],
            "total_assets": [],
            "reward": []
        }
        init_state = np.array(
            [self.initial_amount] 
            + [0] * len(self.assets)
            + self.get_date_vector(self.date_index)
        )
        self.state_memory.append(init_state)
        return init_state

    def log_step(
        self, reason: str, terminal_reward: float=None
        ) -> None:
        """æ‰“å°"""
        if terminal_reward is None:
            terminal_reward = self.account_information["reward"][-1]
        
        assets = self.account_information["total_assets"][-1]
        tmp_retreat_ptc = assets / self.max_total_assets - 1
        retreat_pct = tmp_retreat_ptc if assets < self.max_total_assets else 0
        gl_pct = self.account_information["total_assets"][-1] / self.initial_amount

        rec = [
            self.episode,
            self.date_index - self.starting_point,
            reason,
            f"{self.currency}{'{:0,.0f}'.format(float(self.account_information['cash'][-1]))}",
            f"{self.currency}{'{:0,.0f}'.format(float(assets))}",
            f"{terminal_reward*100:0.5f}%",
            f"{(gl_pct - 1)*100:0.5f}%",
            f"{retreat_pct*100:0.2f}%"
        ]
        self.episode_history.append(rec)
        print(self.template.format(*rec))

    def return_terminal(
        self, reason: str = "Last Date", reward: int = 0
    ) -> Tuple[List, float, bool, dict]:
        """terminal çš„æ—¶å€™æ‰§è¡Œçš„æ“ä½œ"""
        state = self.state_memory[-1]
        self.log_step(reason=reason, terminal_reward=reward)
        gl_pct = self.account_information["total_assets"][-1] / self.initial_amount
        logger.record("environment/GainLoss_pct", (gl_pct - 1) * 100)
        logger.record(
            "environment/total_assets",
            int(self.account_information["total_assets"][-1])
        )
        reward_pct = gl_pct
        logger.record("environment/total_reward_pct", (reward_pct - 1) * 100)
        logger.record("environment/total_trades", self.sum_trades)
        logger.record(
            "environment/avg_daily_trades",
            self.sum_trades / (self.current_step)
        )
        logger.record(
            "environment/avg_daily_trades_per_asset",
            self.sum_trades / (self.current_step) / len(self.assets)
        )
        logger.record("environment/completed_steps", self.current_step)
        logger.record(
            "environment/sum_rewards", np.sum(self.account_information["reward"])
        )
        logger.record(
            "environment/retreat_proportion",
            self.account_information["total_assets"][-1] / self.max_total_assets
        )

        return state, reward, True, {}

    def log_header(self) -> None:
        """Log çš„åˆ—å"""
        if not self.printed_header:
            self.template = "{0:4}|{1:4}|{2:15}|{3:15}|{4:15}|{5:10}|{6:10}|{7:10}"
            # 0, 1, 2, ... æ˜¯åºå·
            # 4, 4, 15, ... æ˜¯å ä½æ ¼çš„å¤§å°
            print(
                self.template.format(
                    "EPISODE",
                    "STEPS",
                    "TERMINAL_REASON",
                    "CASH",
                    "TOT_ASSETS",
                    "TERMINAL_REWARD",
                    "GAINLOSS_PCT",
                    "RETREAT_PROPORTION"
                )
            )
            self.printed_header = True

    def get_reward(self) -> float:
        """è·å–å¥–åŠ±å€¼"""
        if self.current_step == 0:
            return 0
        else:
            assets = self.account_information["total_assets"][-1]
            retreat = 0
            if assets >= self.max_total_assets:
                self.max_total_assets = assets
            else:
                retreat = assets / self.max_total_assets - 1
            reward = assets / self.initial_amount - 1
            reward += retreat
            return reward

    def get_transactions(self, actions: np.ndarray) -> np.ndarray:
        """è·å–å®é™…äº¤æ˜“çš„è‚¡æ•°"""
        self.actions_memory.append(actions)
        actions = actions * self.hmax

        # æ”¶ç›˜ä»·ä¸º 0 çš„ä¸è¿›è¡Œäº¤æ˜“
        actions = np.where(self.closings > 0, actions, 0)

        # å»é™¤è¢«é™¤æ•°ä¸º 0 çš„è­¦å‘Š
        out = np.zeros_like(actions)
        zero_or_not = self.closings != 0
        actions = np.divide(actions, self.closings, out=out, where = zero_or_not)
        
        # ä¸èƒ½å–çš„æ¯”æŒä»“çš„å¤š
        actions = np.maximum(actions, -np.array(self.holdings))

        # å°† -0 çš„å€¼å…¨éƒ¨ç½®ä¸º 0
        actions[actions == -0] = 0

        return actions

    def step(
        self, actions: np.ndarray
    ) -> Tuple[List, float, bool, dict]:
        self.sum_trades += np.sum(np.abs(actions))
        self.log_header()
        if(self.current_step + 1) % self.print_verbosity == 0:
            self.log_step(reason="update")
        if self.date_index == len(self.dates) - 1:
            return self.return_terminal(reward=self.get_reward())
        else:
            begin_cash = self.cash_on_hand
            assert min(self.holdings) >= 0
            assert_value = np.dot(self.holdings, self.closings)
            self.account_information["cash"].append(begin_cash)
            self.account_information["asset_value"].append(assert_value)
            self.account_information["total_assets"].append(begin_cash + assert_value)
            reward = self.get_reward()
            self.account_information["reward"].append(reward)

            transactions = self.get_transactions(actions)
            sells = -np.clip(transactions, -np.inf, 0)
            proceeds = np.dot(sells, self.closings)
            costs = proceeds * self.sell_cost_pct
            coh = begin_cash + proceeds # è®¡ç®—ç°é‡‘çš„æ•°é‡

            buys = np.clip(transactions, 0, np.inf)
            spend = np.dot(buys, self.closings)
            costs += spend * self.buy_cost_pct

            if (spend + costs) > coh: # å¦‚æœä¹°ä¸èµ·
                if self.patient:
#                     self.log_step(reason="CASH SHORTAGE")
                    transactions = np.where(transactions > 0, 0, transactions)
                    spend = 0
                    costs = 0
                else:
                    return self.return_terminal(
                        reason="CASH SHORTAGE", reward=self.get_reward()
                    )
            self.transaction_memory.append(transactions)
            assert (spend + costs) <= coh
            coh = coh - spend - costs
            holdings_updated = self.holdings + transactions
            self.date_index += 1
            state = (
                [coh] + list(holdings_updated) + self.get_date_vector(self.date_index)
            )
            self.state_memory.append(state)
            return state, reward, False, {}

    def get_sb_env(self) -> Tuple[Any, Any]:
        def get_self():
            return deepcopy(self)
        
        e = DummyVecEnv([get_self])
        obs = e.reset()
        return e, obs

    def get_multiproc_env(
        self, n: int = 10
    ) -> Tuple[Any, Any]:
        def get_self():
            return deepcopy(self)
        
        e = SubprocVecEnv([get_self for _ in range(n)], start_method="fork")
        obs = e.reset()
        return e, obs
    
    def save_asset_memory(self) -> pd.DataFrame:
        if self.current_step == 0:
            return None
        else:
            self.account_information["date"] = self.dates[
                -len(self.account_information["cash"]):
            ]
            return pd.DataFrame(self.account_information)
    
    def save_action_memory(self) -> pd.DataFrame:
        if self.current_step == 0:
            return None
        else:
            return pd.DataFrame(
                {
                    "date": self.dates[-len(self.account_information["cash"]):],
                    "actions": self.actions_memory,
                    "transactions": self.transaction_memory
                }
            )